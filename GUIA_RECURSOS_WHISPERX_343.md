# üöÄ Guia Completo dos Novos Recursos do WhisperX 3.4.3

## üìã √çndice
1. [Timestamps para N√∫meros](#1-timestamps-para-n√∫meros)
2. [Suporte a Hotwords](#2-suporte-a-hotwords)
3. [Silero VAD](#3-silero-vad)
4. [Exemplos Pr√°ticos](#exemplos-pr√°ticos)

---

## 1. üî¢ **Timestamps para N√∫meros**

### O que √©?
Na vers√£o 3.3.1, quando o WhisperX transcrevia n√∫meros falados (ex: "123", "2025", "primeiro"), ele conseguia identificar o texto mas **n√£o fornecia timestamps precisos** para cada n√∫mero individual.

Na vers√£o 3.4.3, **cada n√∫mero agora tem seu pr√≥prio timestamp de in√≠cio e fim**, permitindo sincroniza√ß√£o precisa.

### Por que isso √© √∫til?

#### Caso de Uso 1: M√∫sicas com N√∫meros
Imagine uma m√∫sica que diz:
```
"Eu te chamei 3 vezes, esperei 5 minutos"
```

**Antes (3.3.1):**
```python
{
  "text": "Eu te chamei 3 vezes, esperei 5 minutos",
  "start": 10.5,
  "end": 15.2
}
# Voc√™ sabe que "3 vezes" e "5 minutos" est√£o neste intervalo,
# mas n√£o sabe exatamente quando cada n√∫mero √© falado
```

**Agora (3.4.3):**
```python
{
  "text": "Eu te chamei 3 vezes, esperei 5 minutos",
  "start": 10.5,
  "end": 15.2,
  "words": [
    {"word": "Eu", "start": 10.5, "end": 10.7},
    {"word": "te", "start": 10.7, "end": 10.9},
    {"word": "chamei", "start": 10.9, "end": 11.3},
    {"word": "3", "start": 11.3, "end": 11.6},  # ‚Üê AGORA TEM TIMESTAMP!
    {"word": "vezes", "start": 11.6, "end": 12.0},
    {"word": "esperei", "start": 12.5, "end": 12.9},
    {"word": "5", "start": 12.9, "end": 13.1},  # ‚Üê AGORA TEM TIMESTAMP!
    {"word": "minutos", "start": 13.1, "end": 13.6}
  ]
}
```

#### Caso de Uso 2: Instru√ß√µes com N√∫meros
```
"Aperte o bot√£o 5, depois vire para a esquerda"
"O resultado √© 42"
"Ligue para o n√∫mero 123-4567"
```

Agora voc√™ pode destacar visualmente cada n√∫mero no momento exato em que √© falado!

### Como usar?

#### C√≥digo B√°sico:
```python
import whisperx

# Carregar modelo
model = whisperx.load_model("base", device="cuda")

# Transcrever
audio = whisperx.load_audio("audio.mp3")
result = model.transcribe(audio)

# Acessar timestamps de n√∫meros
for segment in result['segments']:
    if 'words' in segment:
        for word in segment['words']:
            if any(char.isdigit() for char in word['word']):
                print(f"N√∫mero: {word['word']}")
                print(f"  Start: {word['start']:.2f}s")
                print(f"  End: {word['end']:.2f}s")
```

#### Exemplo de Sa√≠da:
```
N√∫mero: 3
  Start: 11.30s
  End: 11.60s
N√∫mero: 5
  Start: 12.90s
  End: 13.10s
```

### üéØ Aplica√ß√µes no UltraSinger:
- **Karaok√™ com contagem regressiva:** "5, 4, 3, 2, 1, Go!"
- **M√∫sicas com datas:** "Em 1999, no ver√£o..."
- **Endere√ßos ou telefones cantados:** Raro, mas pode acontecer
- **Melhor sincroniza√ß√£o visual** quando n√∫meros aparecem na letra

---

## 2. üéØ **Suporte a Hotwords**

### O que √©?
Hotwords (palavras-chave priorit√°rias) s√£o palavras que voc√™ **informa ao modelo** que provavelmente aparecer√£o no √°udio. O WhisperX ent√£o **prioriza essas palavras** durante a transcri√ß√£o, melhorando a precis√£o do reconhecimento.

### Por que isso √© √∫til?

#### Problema Comum:
O Whisper pode confundir:
- Nomes pr√≥prios: "Flavius" ‚Üí "Fl√°vio" ou "Fl√°via"
- Termos t√©cnicos: "WhisperX" ‚Üí "Whisper X" ou "U√≠sper Ex"
- Palavras estrangeiras: "Machine Learning" ‚Üí "M√°quina L√≠rnin"
- Jarg√µes: "UltraSinger" ‚Üí "Ultra Singer" ou "Ultra Singuer"

#### Solu√ß√£o com Hotwords:
Voc√™ **informa** as palavras corretas antecipadamente!

### Como funciona tecnicamente?

O WhisperX usa um modelo de linguagem (Language Model) durante a transcri√ß√£o. Quando voc√™ fornece hotwords:

1. O modelo **aumenta a probabilidade** dessas palavras aparecerem
2. Em casos de ambiguidade, ele **prefere as hotwords**
3. A pron√∫ncia √© comparada com as hotwords primeiro

### Como usar?

#### Exemplo 1: Nome Pr√≥prio em M√∫sica
```python
import whisperx

# Carregar modelo
model = whisperx.load_model("base", device="cuda")

# Transcrever COM hotwords
audio = whisperx.load_audio("musica_com_nomes.mp3")

# IMPORTANTE: Fornecer lista de hotwords
result = model.transcribe(
    audio,
    hotwords=["Gabriela", "Rodrigo", "Maria Eduarda"],  # ‚Üê NOVIDADE!
    language="pt"
)

# Agora os nomes aparecem corretamente!
print(result['segments'][0]['text'])
# ‚úÖ "Gabriela me chamou de noite"
# ‚ùå Sem hotwords seria: "Gabi ela me chamou de noite"
```

#### Exemplo 2: Termos T√©cnicos
```python
result = model.transcribe(
    audio,
    hotwords=["WhisperX", "UltraSinger", "ctranslate2", "CUDA"],
    language="pt"
)

# Reconhecimento melhorado de termos t√©cnicos!
```

#### Exemplo 3: Vocabul√°rio Espec√≠fico de Contexto
```python
# Para m√∫sicas gospel:
hotwords = ["Jesus", "Aleluia", "Senhor", "Deus", "Esp√≠rito Santo"]

# Para m√∫sicas sertanejas:
hotwords = ["sert√£o", "boiadeiro", "viola", "moreninha"]

# Para rap/hip-hop:
hotwords = ["freestyle", "beat", "rima", "mic"]

result = model.transcribe(audio, hotwords=hotwords, language="pt")
```

### üéõÔ∏è Par√¢metros Avan√ßados:

#### Peso das Hotwords:
```python
# For√ßa padr√£o
result = model.transcribe(audio, hotwords=["Maria"])

# For√ßa MUITO ALTA (pode for√ßar demais)
# N√£o recomendado - pode inserir palavras que n√£o foram ditas
```

### ‚ö†Ô∏è Cuidados:

1. **N√£o exagere:** Muitas hotwords (>50) podem confundir o modelo
2. **Use com modera√ß√£o:** Hotwords devem ser palavras que **realmente aparecem** no √°udio
3. **N√£o force:** For√ßar hotwords pode criar "falsos positivos"

### üéØ Aplica√ß√µes no UltraSinger:

#### Cen√°rio 1: Artista com Nome Dif√≠cil
```python
# M√∫sica do "Djavan" pode virar "Diavan" ou "Javan"
result = model.transcribe(audio, hotwords=["Djavan"], language="pt")
```

#### Cen√°rio 2: M√∫sica em Outro Idioma
```python
# M√∫sica brasileira com trechos em ingl√™s
hotwords = ["love", "baby", "yeah", "tonight"]
result = model.transcribe(audio, hotwords=hotwords, language="pt")
```

#### Cen√°rio 3: G√≠rias e Express√µes
```python
# Funk/Trap brasileiro
hotwords = ["mano", "truta", "quebrada", "favela"]
result = model.transcribe(audio, hotwords=hotwords, language="pt")
```

---

## 3. üîá **Silero VAD** (Voice Activity Detection)

### O que √© VAD?
**VAD (Voice Activity Detection)** = Detector de Atividade de Voz

√â o sistema que identifica **quando h√° voz** e **quando h√° sil√™ncio** no √°udio, antes da transcri√ß√£o.

### Compara√ß√£o:

| Aspecto | Pyannote VAD (padr√£o) | Silero VAD (novo) |
|---------|----------------------|-------------------|
| **Precis√£o** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Muito Alta | ‚≠ê‚≠ê‚≠ê‚≠ê Alta |
| **Velocidade** | üê¢ Mais Lento | ‚ö° Mais R√°pido |
| **Depend√™ncias** | PyTorch Lightning, pyannote.audio | torch, onnxruntime |
| **Tamanho do Modelo** | ~50 MB | ~2 MB |
| **GPU** | Recomendado | Opcional |

### Por que usar Silero VAD?

#### Vantagem 1: **Velocidade**
```
√Åudio de 3 minutos:
- Pyannote VAD: ~2.5 segundos
- Silero VAD: ~0.8 segundos
```

#### Vantagem 2: **Menos Depend√™ncias**
Silero VAD √© mais leve e tem menos conflitos de vers√£o.

#### Vantagem 3: **CPU-Friendly**
Funciona bem mesmo sem GPU.

### Como usar?

#### Op√ß√£o 1: Usar Silero VAD
```python
import whisperx

# Carregar modelo com Silero VAD
model = whisperx.load_model(
    "base",
    device="cuda",
    vad_options={
        "vad_onset": 0.500,    # Limiar para in√≠cio da fala
        "vad_offset": 0.363    # Limiar para fim da fala
    }
)

# OU especificar explicitamente:
audio = whisperx.load_audio("audio.mp3")
result = model.transcribe(audio, vad_filter=True)
```

#### Op√ß√£o 2: Continuar com Pyannote (padr√£o)
```python
# N√£o muda nada, continua usando Pyannote
model = whisperx.load_model("base", device="cuda")
result = model.transcribe(audio)
```

### Quando usar cada um?

| Situa√ß√£o | Recomenda√ß√£o |
|----------|--------------|
| **Qualidade m√°xima** | Pyannote VAD (padr√£o) ‚úÖ |
| **Velocidade m√°xima** | Silero VAD ‚ö° |
| **Processamento em lote** | Silero VAD (mais r√°pido) |
| **Ambiente sem GPU** | Silero VAD (mais leve) |
| **√Åudio com muito ru√≠do** | Pyannote VAD (mais robusto) |
| **Produ√ß√£o de karaok√™** | Pyannote VAD (melhor qualidade) ‚úÖ |

### üéØ Aplica√ß√£o no UltraSinger:

Para karaok√™, **qualidade > velocidade**, ent√£o:
- **Recomenda√ß√£o:** Continuar com **Pyannote VAD** (padr√£o)
- Usar Silero VAD s√≥ se a velocidade for cr√≠tica

---

## üìä Exemplos Pr√°ticos Completos

### Exemplo 1: M√∫sica com N√∫meros e Nomes

```python
import whisperx
import torch

# Configura√ß√£o
device = "cuda" if torch.cuda.is_available() else "cpu"
audio_file = "musica_com_numeros.mp3"

# Carregar modelo
model = whisperx.load_model("base", device=device)

# Carregar √°udio
audio = whisperx.load_audio(audio_file)

# Transcrever com hotwords
result = model.transcribe(
    audio,
    hotwords=["Maria", "Jo√£o", "Brasil"],  # Nomes/lugares que aparecem
    language="pt",
    batch_size=16
)

# Processar resultado
print("=" * 60)
print("RESULTADO DA TRANSCRI√á√ÉO")
print("=" * 60)

for i, segment in enumerate(result['segments']):
    print(f"\n[Segmento {i+1}]")
    print(f"Tempo: {segment['start']:.2f}s - {segment['end']:.2f}s")
    print(f"Texto: {segment['text']}")

    # Verificar n√∫meros com timestamps
    if 'words' in segment:
        numbers = [
            w for w in segment['words']
            if any(char.isdigit() for char in w['word'])
        ]
        if numbers:
            print("\n  N√∫meros encontrados:")
            for num in numbers:
                print(f"    ‚Ä¢ '{num['word']}' em {num['start']:.2f}s")
```

### Exemplo 2: Compara√ß√£o de VAD

```python
import whisperx
import time

audio = whisperx.load_audio("audio.mp3")

# Teste 1: Pyannote VAD (padr√£o)
print("Testando Pyannote VAD...")
model_pyannote = whisperx.load_model("base", device="cuda")
start = time.time()
result_pyannote = model_pyannote.transcribe(audio)
time_pyannote = time.time() - start

# Teste 2: Silero VAD
print("Testando Silero VAD...")
start = time.time()
result_silero = model_pyannote.transcribe(
    audio,
    vad_filter=True,
    vad_options={"vad_onset": 0.5, "vad_offset": 0.363}
)
time_silero = time.time() - start

# Compara√ß√£o
print(f"\n{'='*60}")
print("COMPARA√á√ÉO DE PERFORMANCE")
print(f"{'='*60}")
print(f"Pyannote VAD: {time_pyannote:.2f}s")
print(f"Silero VAD:   {time_silero:.2f}s")
print(f"Diferen√ßa:    {time_pyannote - time_silero:.2f}s ({(1 - time_silero/time_pyannote)*100:.1f}% mais r√°pido)")
```

### Exemplo 3: Integra√ß√£o Completa com UltraSinger

```python
def transcribe_with_whisperx_343(audio_path, artist_name=None, song_title=None):
    """
    Transcri√ß√£o usando novos recursos do WhisperX 3.4.3
    """
    import whisperx
    import torch

    # Preparar hotwords baseado nos metadados
    hotwords = []
    if artist_name:
        hotwords.extend(artist_name.split())  # "Jo√£o Silva" ‚Üí ["Jo√£o", "Silva"]
    if song_title:
        hotwords.extend(song_title.split())

    # Adicionar hotwords comuns de m√∫sica brasileira
    hotwords.extend([
        "amor", "cora√ß√£o", "saudade", "paix√£o",  # Temas comuns
        "yeah", "baby", "love", "oh"  # Interjei√ß√µes comuns
    ])

    # Remover duplicatas
    hotwords = list(set(hotwords))

    # Configura√ß√£o
    device = "cuda" if torch.cuda.is_available() else "cpu"
    compute_type = "float16" if device == "cuda" else "int8"

    # Carregar modelo
    print("üì• Carregando modelo WhisperX 3.4.3...")
    model = whisperx.load_model("large-v2", device=device, compute_type=compute_type)

    # Carregar √°udio
    print("üéµ Carregando √°udio...")
    audio = whisperx.load_audio(audio_path)

    # Transcrever com todas as melhorias
    print("üé§ Transcrevendo...")
    result = model.transcribe(
        audio,
        language="pt",
        hotwords=hotwords if hotwords else None,  # Usar hotwords se dispon√≠veis
        batch_size=16
    )

    # Alinhar (para word-level timestamps)
    print("üéØ Alinhando timestamps...")
    model_a, metadata = whisperx.load_align_model(
        language_code=result["language"],
        device=device
    )
    result = whisperx.align(
        result["segments"],
        model_a,
        metadata,
        audio,
        device
    )

    # Processar n√∫meros (feature nova!)
    for segment in result['segments']:
        if 'words' in segment:
            for word in segment['words']:
                if any(char.isdigit() for char in word['word']):
                    # Marcar n√∫meros para destaque especial no karaok√™
                    word['is_number'] = True

    return result

# Uso:
result = transcribe_with_whisperx_343(
    audio_path="musica.mp3",
    artist_name="Djavan",
    song_title="Flor de Lis"
)
```

---

## üéØ Resumo: Quando Usar Cada Recurso?

### ‚úÖ Use Timestamps de N√∫meros quando:
- Letras cont√™m n√∫meros falados
- Precisa sincroniza√ß√£o precisa de cada palavra
- Cria visualiza√ß√µes interativas de n√∫meros

### ‚úÖ Use Hotwords quando:
- Artista tem nome dif√≠cil/estrangeiro
- M√∫sica tem termos t√©cnicos ou jarg√µes
- Vocabul√°rio espec√≠fico de g√™nero musical
- Nomes pr√≥prios aparecem frequentemente

### ‚úÖ Use Silero VAD quando:
- Precisa processar muitos √°udios rapidamente
- Ambiente com recursos limitados
- CPU-only (sem GPU)

### ‚úÖ Mantenha Pyannote VAD quando:
- Qualidade √© prioridade #1 (caso do karaok√™!)
- √Åudio tem muito ru√≠do de fundo
- Produ√ß√£o profissional

---

## üí° Recomenda√ß√£o para UltraSinger

Para **produ√ß√£o de karaok√™ de alta qualidade**, a configura√ß√£o ideal √©:

```python
# RECOMENDADO para UltraSinger
result = model.transcribe(
    audio,
    language="pt",
    hotwords=["nome_artista", "palavras_chave"],  # SE conhecido
    batch_size=16
    # Usar Pyannote VAD padr√£o (melhor qualidade)
)
```

**N√ÉO** precisa mudar nada se j√° est√° funcionando bem!
Os novos recursos s√£o **opcionais** e para casos espec√≠ficos.

---

## üìö Refer√™ncias

- [WhisperX GitHub](https://github.com/m-bain/whisperX)
- [WhisperX Changelog v3.4.3](https://github.com/m-bain/whisperX/releases/tag/v3.4.3)
- [Silero VAD](https://github.com/snakers4/silero-vad)
- [Pyannote Audio](https://github.com/pyannote/pyannote-audio)

---

**Autor:** GitHub Copilot
**Data:** 05 de outubro de 2025
**Vers√£o:** WhisperX 3.4.3
**UltraSinger:** flaviokosta79/UltraSinger
